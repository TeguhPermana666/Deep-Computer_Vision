{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet-16\n",
    "\n",
    "https://www.kaggle.com/code/blurredmachine/vggnet-16-architecture-a-complete-guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has released a series of convolutional network models beginning with VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original purpose of VGG's research on the depth of convolutional networks is to understand how the depth of convolutional networks affects the accuracy and accuracy of large-scale image classification and recognition.\n",
    "\n",
    "- Deep-16 CNN), in order to deepen the number of network layers and to avoid too many parameters, a small 3x3 convolution kernel is used in all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arsitecture :\n",
    "http://ethereon.github.io/netscope/#/gist/dc5003de6943ea5a6b8b\n",
    "\n",
    "![Vggnet.png](images\\cnn\\vggnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vggnet_pathway.png](images\\cnn\\vggnet_pathway.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vggnet.png](images\\cnn\\vggnet_arsitecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setiap conv layer dalam AlexNet yang berisikan hanya satu convolution dan size sebuah convolution kernel adalah 77, pada VGGNet, setiap convolution layer berisikan 2 sampai 4 convolution operations. Size conv kernel adalah 33,the convolution step size is 1 the pooling kernel adalah 2*2, dan setiap step size adalah 2, abvious peningkatan dari VGGNet adalah mengurangi ukuran dari convolution kernel dan meningkatkan sebuah number dari convolution layers.\n",
    "\n",
    "![vggnet_schmea.jpeg](images\\cnn\\vggnet_schema.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menggunakan multiple convolution layers dengan smaller convolution kernels alih-alih dari larger conv layer dengan conv kernel bisa di reduce parameters pada saty tangan, and percayai persamaan untuk more non -linear mapping, yang incereases fit expression abillity\n",
    "\n",
    "![flow.png](images\\cnn\\activation_flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = Input((224,224,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = Conv2D(filters=64, kernel_size=(3,3),padding='same',activation='relu')(_input)\n",
    "conv2 = Conv2D(filters=64, kernel_size=(3,3), padding='same',activation='relu')(conv1)\n",
    "pool1 = MaxPooling2D((2,2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(filters=128,kernel_size=(3,3),padding='same',activation='relu')(pool1)\n",
    "conv4 = Conv2D(filters=128,kernel_size=(3,3),padding='same',activation='relu')(conv3)\n",
    "pool2 = MaxPooling2D((2,2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(filters=256,kernel_size=(3,3),padding='same',activation='relu')(pool2)\n",
    "conv6 = Conv2D(filters=256,kernel_size=(3,3),padding='same',activation='relu')(conv5)\n",
    "conv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "pool3 = MaxPooling2D((2,2))(conv7)\n",
    "\n",
    "conv8 = Conv2D(filters=512,kernel_size=(3,3),padding='same',activation='relu')(pool3)\n",
    "conv9 = Conv2D(filters=512,kernel_size=(3,3),padding='same',activation='relu')(conv8)\n",
    "conv10 = Conv2D(filters=512,kernel_size=(3,3),padding='same',activation='relu')(conv9)\n",
    "pool4 = MaxPooling2D((2,2))(conv10)\n",
    "\n",
    "conv11 = Conv2D(filters=512,kernel_size=(3,3),padding='same',activation='relu')(pool4)\n",
    "conv12 = Conv2D(filters=512,kernel_size=(3,3),padding='same',activation='relu')(conv11)\n",
    "conv13 = Conv2D(filters=512,kernel_size=(3,3),padding='same',activation='relu')(conv12)\n",
    "pool5 = MaxPooling2D((2,2))(conv13)\n",
    "\n",
    "\n",
    "flat = Flatten()(pool5)\n",
    "dense1 = Dense(4096,activation='relu')(flat)\n",
    "dense2 = Dense(4096,activation='relu')(dense1)\n",
    "output = Dense(1000, activation='softmax')(dense2)\n",
    "\n",
    "vgg16_model = Model(inputs=_input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Model\n",
    "\n",
    "- Keras library selalu menyediakan pre-trained model yang mana hanya satu yang bisa di load sebuah saved model weights, dan menggunakan different purposes : Transfer Learning, image feature extraction, and object detection.Bisa di load sebuah model architecture diberikan ke dalam sebuah library, dan selanjutnya di tambahkan semua weights untuk respective layers\n",
    "\n",
    "- Sebelum menggunakan pretrained models, lets write a few function yang mana digunakan untuk membuat prediksi.Pertama : load some images and preprocess them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "img1 = \"../input/flowers-recognition/flowers/tulip/10094729603_eeca3f2cb6.jpg\"\n",
    "img2 = \"../input/flowers-recognition/flowers/dandelion/10477378514_9ffbcec4cf_m.jpg\"\n",
    "img3 = \"../input/flowers-recognition/flowers/sunflower/10386540696_0a95ee53a8_n.jpg\"\n",
    "img4 = \"../input/flowers-recognition/flowers/rose/10090824183_d02c613f10_m.jpg\"\n",
    "imgs = [img1, img2, img3, img4]\n",
    "\n",
    "def _load_image(img_path):\n",
    "    img = image.load_img(img_path,target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def _get_predictions(_model):\n",
    "    f, ax = plt.subplots(1,4)\n",
    "    f.set_size_inches(80,40)\n",
    "    for i in range(4):\n",
    "        ax[i].imshow(Image.open(imgs[i]).resize((200,200),Image.ANTIALIAS))\n",
    "    plt.show()\n",
    "    \n",
    "    f, axes = plt.subplots(1,4)\n",
    "    f.set_size_inches(80,20)\n",
    "    for i, img_path in enumerate(imgs):\n",
    "        img = _load_image(img_path)\n",
    "        preds = decode_predictions(_model.predict(img),top=3)[0]\n",
    "        b = sns.barplot(y=[c[1] for c in preds],x=[c[2] for c in preds],color=\"gray\", ax=axes[i])\n",
    "        b.tick_params(labelsize=55)\n",
    "        f.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77f82ba0137ec3dae2f85316aa0d614a6a0840ddb68c06667e94242579b14d21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
